{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1><center>HackerCamp Summer 2018 - Innovaccer </center></h1>\n",
    "<h2><center>Submitted By</center></h2>\n",
    "<h3><center>Dhruvraj Singh Rawat</center></h3>\n",
    "<h3><center>LNM Institute of Information Technology</center></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>The main aim is to create a robust model which can Identify Variation in names and identifying a unique person and hence solve deduplication of records comming from multiple sources.<center>\n",
    "\n",
    "<center>I have solved this problem using <font color=green>Unsupervised Learning</font> with the help of <font color=green>K-Means Clustering Algorithm</font> <center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Dataset and Exploring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd #Importing Pandas library for Data-Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('dataset/Deduplication Problem - Sample Dataset.csv') #Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ln</th>\n",
       "      <th>dob</th>\n",
       "      <th>gn</th>\n",
       "      <th>fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMITH JR</td>\n",
       "      <td>01-03-68</td>\n",
       "      <td>F</td>\n",
       "      <td>WILLIAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROTHMEYER JR</td>\n",
       "      <td>01-03-68</td>\n",
       "      <td>F</td>\n",
       "      <td>WILLIAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASBY JR</td>\n",
       "      <td>01-03-68</td>\n",
       "      <td>F</td>\n",
       "      <td>WILLIAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SALTER JR</td>\n",
       "      <td>01-03-68</td>\n",
       "      <td>F</td>\n",
       "      <td>WILLIAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SALTER JR</td>\n",
       "      <td>01-03-68</td>\n",
       "      <td>F</td>\n",
       "      <td>WILLIAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BLAND JR</td>\n",
       "      <td>21-02-62</td>\n",
       "      <td>F</td>\n",
       "      <td>WILLIAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BLAND JR</td>\n",
       "      <td>21-02-62</td>\n",
       "      <td>F</td>\n",
       "      <td>WILLIAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BLAND JR</td>\n",
       "      <td>21-02-62</td>\n",
       "      <td>F</td>\n",
       "      <td>WILLIAM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ln       dob gn       fn\n",
       "0      SMITH JR  01-03-68  F  WILLIAM\n",
       "1  ROTHMEYER JR  01-03-68  F  WILLIAM\n",
       "2       ASBY JR  01-03-68  F  WILLIAM\n",
       "3     SALTER JR  01-03-68  F  WILLIAM\n",
       "4     SALTER JR  01-03-68  F  WILLIAM\n",
       "5      BLAND JR  21-02-62  F  WILLIAM\n",
       "6      BLAND JR  21-02-62  F  WILLIAM\n",
       "7      BLAND JR  21-02-62  F  WILLIAM"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(8) #Visualizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ln</th>\n",
       "      <th>dob</th>\n",
       "      <th>gn</th>\n",
       "      <th>fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>MICHAELSON JR</td>\n",
       "      <td>07-10-37</td>\n",
       "      <td>M</td>\n",
       "      <td>HAROLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>86</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ln       dob   gn      fn\n",
       "count             112       112  112     112\n",
       "unique             37        24    2      28\n",
       "top     MICHAELSON JR  07-10-37    M  HAROLD\n",
       "freq               22        24   86      24"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ln     37\n",
       "dob    24\n",
       "gn      2\n",
       "fn     28\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing the Text & Seperating Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer #Importing CountVectorizer for Vectorizing the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting the Dob to different coloumn\n",
    "\n",
    "df['day']=pd.to_datetime(df['dob']).dt.day\n",
    "df['month']=pd.to_datetime(df['dob']).dt.month\n",
    "df['year']=pd.to_datetime(df['dob']).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop('dob',axis=1,inplace=True) #After splitting dob droping the original column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting Gender the categorical value into 2 columns -Male and Female\n",
    "\n",
    "gender_dummie=pd.get_dummies(df['gn']) \n",
    "df=pd.concat([df,gender_dummie],axis=1)\n",
    "df.drop('gn',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Vectorizing the First-Name and Last-Name\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "Vect1=vectorizer.fit_transform(df['fn'])\n",
    "vectorizer.get_feature_names()\n",
    "FirstNameCol=pd.DataFrame(Vect1.toarray(),columns=vectorizer.get_feature_names())\n",
    "\n",
    "\n",
    "vectorizer=CountVectorizer()\n",
    "Vect2=vectorizer.fit_transform(df['ln'])\n",
    "SecondNameCol=pd.DataFrame(Vect2.toarray(),columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Final=pd.concat([df,FirstNameCol,SecondNameCol],axis=1) #Concatting the Vectorized First-Name & Last-Name to the original df\n",
    "Final.drop(['ln','fn'],axis=1,inplace=True) #Dropping the Non-vectorized First-Name & Last-Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Manual Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are creating a MANUAL feature ! This feature is created to teach our model the SIMILARITY between a Name with other Names in the data-set.This Feature was created because it was noted that model was clustering only SAME-NAMES together not the SIMILAR-NAMES.\n",
    "\n",
    "I have increased the Bias of the Similarity coef 3 times to that when two names have same word,so as model can understand this concept more effectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity #Using cosine similarity for finding similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_fn=[]\n",
    "len_ln=[]\n",
    "\n",
    "for i in range(len(df)):\n",
    "    len_fn.append('fn'+str(i)) # creating the column label for fn's\n",
    "    len_ln.append('ln'+str(i)) # creating the Column label for ln's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn_df=pd.DataFrame(3*cosine_similarity(Vect1[:], Vect1),columns=len_fn) #finding similarity coef of a given fn with other fn's\n",
    "ln_df=pd.DataFrame(3*cosine_similarity(Vect2[:], Vect2),columns=len_ln) #finding similarity coef of a given ln with other ln's\n",
    "\n",
    "Final_1=pd.concat([Final,fn_df,ln_df],axis=1) #concatting the similarity coef's to the main dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Evaluation of the Model we are using the Silhouette Coefficient's that is calculated using the mean intra-cluster distance (a) and the mean nearest-cluster distance (b) for each sample. The Silhouette Coefficient for a sample is (b - a) / max(a, b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Silhouette_score function returns the mean Silhouette Coefficient over all samples.\n",
    "# To obtain the values for each sample, we used silhouette_samples.\n",
    "from sklearn.metrics import silhouette_score,silhouette_samples \n",
    "\n",
    "from sklearn.cluster import KMeans # Importing KMeans clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are passing different value of cluster (k) and finding the Silhouette for the same\n",
    "score=[]\n",
    "for i in range(2,100):\n",
    "    Kmeans_model=KMeans(n_clusters=i).fit(Final_1)\n",
    "    labels=Kmeans_model.labels_\n",
    "    score.append(silhouette_score(Final_1,labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Optimum number of clusters have been found to be 46 with Silhouette Score of 0.7709069728197805\n"
     ]
    }
   ],
   "source": [
    "print (\"The Optimum number of clusters have been found to be \"+str(score.index(max(score))+2)+\" with Silhouette Score of \"+str(max(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fitting the KMeans Model to Cluster Number having Highest Silhouette Score\n",
    "Kmeans_model=KMeans(n_clusters=score.index(max(score))+2).fit(Final_1)\n",
    "labels=Kmeans_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# <EXTRA> Creating a CSV-File for better understand which samples are clustering to which cluster \n",
    "cluster_no=pd.DataFrame(labels,columns=['Cluster Number'])\n",
    "pd.concat([df,cluster_no],axis=1).to_csv(\"Insider.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe that contain only those samples that have highest Silhouette Score for a given cluster.\n",
    "# Thus effectively removing all the duplicate samples and leaving those which sample which represents a given Cluster accurately\n",
    "df1=pd.read_csv('dataset/Deduplication Problem - Sample Dataset.csv')\n",
    "rst=pd.DataFrame({'Cluster No':labels,'Silhouette Score':silhouette_samples(Final_1,labels)})\n",
    "result=pd.concat([df1,rst],axis=1)\n",
    "result.drop_duplicates(subset=['Cluster No','Silhouette Score'],keep='first',inplace=True)\n",
    "result.sort_values(by=['Silhouette Score','Cluster No'],ascending=[False,True],inplace=True)\n",
    "result.drop_duplicates(subset=['Cluster No'],keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.drop(['Cluster No','Silhouette Score'],axis=1).to_csv('result.csv',index=False) # Saving the above df to a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
